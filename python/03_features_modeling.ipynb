#   - split data by time (first 80% train, last 20% test)
#   - train: logistic regression + random forest (+ xgboost if available)
#   - compute: accuracy, f1, roc-auc
#   - export: reports/figures/model_performance_table.png

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# 1) load dataset
df = pd.read_csv("modeling_dataset.csv")
df["date"] = pd.to_datetime(df["date"])
df = df.sort_values("date").reset_index(drop=True)

# quick check: we need a target column
if "target_high_volatility" not in df.columns:
    raise ValueError("target_high_volatility is missing. Create it in R first (modeling_dataset.csv).")

df["target_high_volatility"] = df["target_high_volatility"].astype(int)

# if event_window is missing, we add it as 0 (so the code still runs)
if "event_window" not in df.columns:
    df["event_window"] = 0

# 2) create lag features (past info only)
# these lags help the model learn from recent history
for lag in [1, 2, 3]:
    if "log_return" in df.columns:
        df[f"log_return_lag{lag}"] = df["log_return"].shift(lag)
    if "epu_index" in df.columns:
        df[f"epu_lag{lag}"] = df["epu_index"].shift(lag)

# after lags, first rows become NA -> we drop them
df = df.dropna().reset_index(drop=True)

# 3) choose features
feature_cols = [
    "log_return_lag1", "log_return_lag2", "log_return_lag3",
    "epu_lag1", "epu_lag2", "epu_lag3",
    "event_window"
]

# add extra features if they exist (nice to have)
for c in ["garch_sigma", "vol_7d", "vol_14d", "vol_30d"]:
    if c in df.columns:
        feature_cols.append(c)

X = df[feature_cols].copy()
y = df["target_high_volatility"].copy()

print("features used:", feature_cols)
print("total rows:", len(df))

# 4) time split (first 80% train / last 20% test)
split_idx = int(len(df) * 0.8)

X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

print("train size:", len(X_train))
print("test size :", len(X_test))
print("test date range:", df["date"].iloc[split_idx].date(), "to", df["date"].iloc[-1].date())

# 5) train models
models = {}

# logistic regression (simple baseline)
logreg = LogisticRegression(max_iter=2000)
logreg.fit(X_train, y_train)
models["logistic_regression"] = logreg

# random forest (stronger baseline)
rf = RandomForestClassifier(n_estimators=400, random_state=42)
rf.fit(X_train, y_train)
models["random_forest"] = rf

# xgboost (optional)
try:
    from xgboost import XGBClassifier

    xgb = XGBClassifier(
        n_estimators=400,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=42,
        eval_metric="logloss"
    )
    xgb.fit(X_train, y_train)
    models["xgboost"] = xgb
except Exception:
    print("xgboost not available, skipping it (this is fine).")

print("trained models:", list(models.keys()))

# 6) evaluate: accuracy, f1, roc-auc
rows = []

for name, model in models.items():
    preds = model.predict(X_test)

    acc = accuracy_score(y_test, preds)
    f1 = f1_score(y_test, preds)

    # roc-auc needs probabilities
    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X_test)[:, 1]
        roc = roc_auc_score(y_test, probs)
    else:
        roc = np.nan

    rows.append([name, acc, f1, roc])

results = pd.DataFrame(rows, columns=["model", "accuracy", "f1", "roc_auc"])
results = results.sort_values("f1", ascending=False).reset_index(drop=True)

print("\nmodel results:")
print(results)

# 7) export results table as image
os.makedirs("reports/figures", exist_ok=True)

fig, ax = plt.subplots(figsize=(8, 2.2))
ax.axis("off")

table_values = np.round(results[["accuracy", "f1", "roc_auc"]].values, 3)
row_labels = results["model"].tolist()

ax.table(
    cellText=table_values,
    colLabels=["accuracy", "f1", "roc_auc"],
    rowLabels=row_labels,
    loc="center"
)

plt.tight_layout()
plt.savefig("reports/figures/model_performance_table.png", dpi=200)
plt.show()

print("saved: reports/figures/model_performance_table.png")

# 8) pick best model 
best_model_name = results.iloc[0]["model"]
best_model = models[best_model_name]

print("best model:", best_model_name)
